# -*- coding: utf-8 -*-
"""Copy of In Care Out Care Classification-Random Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c3Zmet-vl_JKd4HYN1WlJdVz7k809z1z
"""

!python --version

# Installing rectified adam

!pip install keras-rectified-adam
from keras_radam import RAdam

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
import tensorflow as tf

import random
from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV
from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, RobustScaler
from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix, precision_score, recall_score

import pandas
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold
from sklearn.neighbors import KNeighborsClassifier

import pickle
import dill

# To ignore unwanted warnings
import warnings
warnings.filterwarnings('ignore')

# for styling
plt.style.use('seaborn-whitegrid')

"""# **Eksplorasi data**
**Mengunggah data dan inisialisasi awal**


"""

data = pd.read_csv('/content/data-ori.csv')
data.head(10)

"""**Eksplorasi fitur**"""

# Checking features
print(f"Dataset mengandung {data.shape[0]} baris dan {data.shape[1]} kolom")

num_features = [feat for feat in data if data[feat].dtype != object]
cat_features = [feat for feat in data if data[feat].dtype == object]

print(f"Jumlah fitur : {len(num_features+cat_features)}")
print(f"Jumlah fitur numerik : {len(num_features)}")
print(f"Jumlah fitur kategori : {len(cat_features)}\n")

# Checking num_features
data[num_features].describe()

# Checking empty data
data.isnull().sum().sort_values(ascending=False)

"""#**Preprocessing Data**"""

def preprocess(df):
    df = df.copy()
    
    # Binary encoding 
    df['SEX'] = [0 if x == 'F' else 1 for x in df['SEX']]
    df['SOURCE'] = [1 if x == 'out' else 0 for x in df['SOURCE']]

    # Dividing data
    y = df['SOURCE']
    X = df.drop('SOURCE', axis=1)

    # Checking numbers of the data 
    print(X.value_counts())
    print(y.value_counts())
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=42)

    # Scaling data using maxminscaler
    scaler = MinMaxScaler(feature_range=(0,1))
    scaler.fit(X_train)
    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)
    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns) 

    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess(data)

X_train.head(10)

y_train.value_counts()

# for y in y_train:
#   if y == 1:
#     print('true')
#   print('false')

print(X_train.shape)
print(X_test.shape)

"""#**Define and Training the Model**"""

# Define evaluation matrix 
def evaluation(y, y_hat, title = 'Confusion Matrix'):
    cm = confusion_matrix(y, y_hat)
    precision = precision_score(y, y_hat)
    recall = recall_score(y, y_hat)
    accuracy = accuracy_score(y,y_hat)
    f1 = f1_score(y,y_hat)
    print('Recall: ', recall)
    print('Accuracy: ', accuracy)
    print('Precision: ', precision)
    print('F1: ', f1)
    sns.heatmap(cm,  cmap= 'PuBu', annot=True, fmt='g', annot_kws=    {'size':20})
    plt.xlabel('predicted', fontsize=18)
    plt.ylabel('actual', fontsize=18)
    plt.title(title, fontsize=18)
    
    plt.show();

# Define cross validation 
def cross_validate(classifier, cv):
    pipeline = Pipeline(steps=[
        ('classifier', classifier)
    ])
    train_acc = []
    test_acc = []
    for train_ind, val_ind in cv.split(X_train, y_train):
        X_t, y_t = X_train.iloc[train_ind,:], y_train.iloc[train_ind]
        pipeline.fit(X_t, y_t)
        y_hat_t = pipeline.predict(X_t)
        train_acc.append(accuracy_score(y_t, y_hat_t))
        X_val, y_val = X_train.iloc[val_ind,:], y_train.iloc[val_ind]
        y_hat_val = pipeline.predict(X_val)
        test_acc.append(accuracy_score(y_val, y_hat_val))
    print(evaluation(y_val, y_hat_val))
    print('Training Accuracy: {}'.format(np.mean(train_acc)))
    print('\n')
    print('Validation Accuracy: {}'.format(np.mean(test_acc)))
    print('\n')

cross_validate(RandomForestClassifier(), KFold())

# Define grid search 
def grid_search(classifier, param_grid, cv):
    search = GridSearchCV(Pipeline(steps=[
        ('classifier', classifier)
    ]), param_grid, cv=cv)
    train_acc = []
    test_acc = []
    for train_ind, val_ind in cv.split(X_train, y_train):
        X_t, y_t = X_train.iloc[train_ind,:], y_train.iloc[train_ind]
        search.fit(X_t, y_t)
        y_hat_t = search.predict(X_t)
        train_acc.append(accuracy_score(y_t, y_hat_t))
        X_val, y_val = X_train.iloc[val_ind,:], y_train.iloc[val_ind]
        y_hat_val = search.predict(X_val)
        test_acc.append(accuracy_score(y_val, y_hat_val))
    print(evaluation(y_val, y_hat_val))
    print('Training Accuracy: {}'.format(np.mean(train_acc)))
    print('\n')
    print('Validation Accuracy: {}'.format(np.mean(test_acc)))
    print('\n')
    print('Grid Search Best Params:')
    print('\n')
    print(search.best_params_)
    return search.best_params_

# Variation of parameter
parameter_grid = {'classifier__n_estimators': [100, 200, 300, 500, 700],
                     'classifier__max_depth':[10, 50, 75, 90, 150],
                     'classifier__min_samples_split': [2, 5, 10, 15],
                     'classifier__min_samples_leaf': [1, 2, 10, 15]}

final_parameter_grid = grid_search(RandomForestClassifier(), parameter_grid, KFold())

# # Final parameter grid
# final_parameter_grid = {'classifier__n_estimators': [200],
#                         'classifier__random_state':[42],
#                         'classifier__max_depth':[180],
#                         'classifier__min_samples_split': [2],
#                         'classifier__min_samples_leaf': [2]}

final_parameter_grid = {'classifier__n_estimators': [100],
                        'classifier__max_depth':[80],
                        'classifier__random_state':[42],
                     'classifier__min_samples_split': [2],
                     'classifier__min_samples_leaf': [2]}
print(final_parameter_grid)

# Predict final pipeline on test data
final_pipeline = GridSearchCV(Pipeline(steps=[
        ('classifier', RandomForestClassifier())
    ]), final_parameter_grid, cv=KFold())

final_pipeline.fit(X_train, y_train)
train_pred = final_pipeline.best_estimator_.predict(X_train)
print('Evaluation on training data \n')
print(evaluation(y_train, train_pred))
print('\n')

test_pred = final_pipeline.best_estimator_.predict(X_test)
print('Evaluation on testing data \n')
print(evaluation(y_test, test_pred))

# Save and Load Model using joblib
import joblib

joblib.dump(final_pipeline, 'saved_model.pkl')

joblib.load("saved_model.pkl")